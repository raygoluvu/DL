{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og8Kzb6FZka4"
      },
      "source": [
        "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gve05Q_DZka5"
      },
      "source": [
        "Before we start, please put your name and SID in following format: <br>\n",
        ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn1UiTcxZka6"
      },
      "source": [
        "**Your Answer:**    \n",
        "Hi I'm 池品叡, B094020030."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWMWW8Ab_345"
      },
      "source": [
        "## Google Colab Setup\n",
        "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
        "\n",
        "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um5DJvBwb6xT"
      },
      "source": [
        "# Data Setup (5 points)\n",
        "\n",
        "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
        "\n",
        "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "oHkeNUOKiFbP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def rotate_img(img, rot):\n",
        "    if rot == 0: # 0 degrees rotation\n",
        "        return img\n",
        "    #######################################################################\n",
        "    #        TODO: Implement rotate_img() - return the rotated img        #\n",
        "    #######################################################################\n",
        "    elif rot == 1:\n",
        "        return transforms.functional.rotate(img, 90)\n",
        "    elif rot == 2:\n",
        "        return transforms.functional.rotate(img, 180)\n",
        "    elif rot == 3:\n",
        "        return transforms.functional.rotate(img, 270)\n",
        "    else:\n",
        "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
        "\n",
        "    #######################################################################\n",
        "    #                           End of your code                          #\n",
        "    #######################################################################\n",
        "\n",
        "class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n",
        "\n",
        "    def __init__(self, root, train, download, transform) -> None:\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image, cls_label = super().__getitem__(index)\n",
        "\n",
        "        # randomly select image rotation\n",
        "        rotation_label = random.choice([0, 1, 2, 3])\n",
        "        image_rotated = rotate_img(image, rotation_label)\n",
        "\n",
        "        rotation_label = torch.tensor(rotation_label).long()\n",
        "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCBSpNWpb8uw",
        "outputId": "cf6b93ec-7dc1-4ace-f7e3-33dd72c4d3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = CIFAR10Rotation(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = CIFAR10Rotation(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOCWMyGhVOJB"
      },
      "source": [
        "Show some example images and rotated images with labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "A9wN4BJWVMzB",
        "outputId": "5ebfd530-c07a-4880-b7f8-b84e67158c09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class labels:  truck deer  car   plane\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rotation labels:  90    0     90    270  \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "rot_classes = ('0', '90', '180', '270')\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    # unnormalize\n",
        "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n",
        "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, rot_images, rot_labels, labels = next(dataiter)\n",
        "\n",
        "# print images and rotated images\n",
        "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
        "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
        "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unCucbHexG4W"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "pptQRpqK0rOl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_test(net, testloader, criterion, task):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    avg_test_loss = 0.0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for images, images_rotated, labels, cls_labels in testloader:\n",
        "            if task == 'rotation':\n",
        "              images, labels = images_rotated.to(device), labels.to(device)\n",
        "            elif task == 'classification':\n",
        "              images, labels = images.to(device), cls_labels.to(device)\n",
        "            #######################################################################\n",
        "            # TODO: Calculate outputs by running images through the network       #\n",
        "            # The class with the highest energy is what we choose as prediction   #\n",
        "            #######################################################################\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1) # Get the prediction result.\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            #######################################################################\n",
        "            #                           End of your code                          #\n",
        "            #######################################################################\n",
        "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
        "    print('TESTING:')\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "hf698c16A9k5"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lYdnb1Wsta_"
      },
      "source": [
        "# Train a ResNet18 on the rotation task (9 points)\n",
        "\n",
        "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "knAiwdURvBHk",
        "outputId": "b927de4e-aff8-4203-b5bc-1a5eba36e522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j08jbdSQZka9"
      },
      "source": [
        "### Notice: You should not use pretrained weights from ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "235MEIUgsv65",
        "outputId": "4c0a8d01-a9aa-4dd5-8a46-ecffa95d4437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "net = resnet18(weights = None, num_classes=4) # Do not modify this line.\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "Vuhiw0ZoszAd"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "################################################################################\n",
        "# TODO: Define loss and optmizer functions                                     #\n",
        "# Try any loss or optimizer function and learning rate to get better result    #\n",
        "# hint: torch.nn and torch.optim                                               #\n",
        "################################################################################\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "WleH-YBgs0rq"
      },
      "outputs": [],
      "source": [
        "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
        "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
        "\n",
        "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        running_total = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        net.train()\n",
        "\n",
        "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
        "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
        "            ######################################################################################################\n",
        "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #\n",
        "            # TODO: Zero the parameter gradients                                                                 #\n",
        "            # TODO: forward + backward + optimize                                                                #\n",
        "            # TODO: Get predicted results                                                                        #\n",
        "            ######################################################################################################\n",
        "            inputs = torch.zeros(len(imgs))\n",
        "            labels = torch.zeros(len(cls_label))\n",
        "            if task == 'rotation':\n",
        "              inputs = imgs_rotated.to(device)\n",
        "              labels = rotation_label.to(device)\n",
        "\n",
        "            elif task == 'classification':\n",
        "              inputs = imgs.to(device)\n",
        "              labels = cls_label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            ######################################################################################################\n",
        "            #                               End of your code                                                     #\n",
        "            ######################################################################################################\n",
        "\n",
        "\n",
        "            # print statistics\n",
        "            print_freq = 100\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # calc acc\n",
        "            running_total += labels.size(0)\n",
        "            running_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
        "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
        "                start_time = time.time()\n",
        "        ######################################################################################################\n",
        "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
        "        ######################################################################################################\n",
        "        run_test(net=net, testloader=testloader, criterion= criterion, task = task)\n",
        "        net.eval()\n",
        "        ######################################################################################################\n",
        "        #                               End of your code                                                     #\n",
        "        ######################################################################################################\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.load('B094020030_rot_mdl.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "2u4AsfAKtaQS",
        "outputId": "34929bc2-aec2-4219-aa6c-848d48a1a160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.274 acc: 43.03 time: 6.48\n",
            "[1,   200] loss: 1.128 acc: 51.05 time: 7.10\n",
            "[1,   300] loss: 1.107 acc: 51.54 time: 7.11\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 56.42 %\n",
            "Average loss on the 10000 test images: 1.024\n",
            "[2,   100] loss: 1.054 acc: 54.64 time: 6.24\n",
            "[2,   200] loss: 1.025 acc: 56.62 time: 6.69\n",
            "[2,   300] loss: 1.015 acc: 56.87 time: 7.19\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 58.61 %\n",
            "Average loss on the 10000 test images: 0.986\n",
            "[3,   100] loss: 0.984 acc: 58.45 time: 6.68\n",
            "[3,   200] loss: 0.961 acc: 59.71 time: 6.98\n",
            "[3,   300] loss: 0.957 acc: 59.40 time: 7.20\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.27 %\n",
            "Average loss on the 10000 test images: 0.901\n",
            "[4,   100] loss: 0.936 acc: 61.32 time: 6.68\n",
            "[4,   200] loss: 0.932 acc: 61.03 time: 7.06\n",
            "[4,   300] loss: 0.917 acc: 61.82 time: 7.03\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.25 %\n",
            "Average loss on the 10000 test images: 0.880\n",
            "[5,   100] loss: 0.915 acc: 61.82 time: 6.71\n",
            "[5,   200] loss: 0.892 acc: 63.08 time: 6.83\n",
            "[5,   300] loss: 0.889 acc: 63.19 time: 7.23\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.96 %\n",
            "Average loss on the 10000 test images: 0.862\n",
            "[6,   100] loss: 0.868 acc: 63.77 time: 6.42\n",
            "[6,   200] loss: 0.858 acc: 64.73 time: 6.77\n",
            "[6,   300] loss: 0.857 acc: 64.57 time: 6.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 66.12 %\n",
            "Average loss on the 10000 test images: 0.827\n",
            "[7,   100] loss: 0.852 acc: 65.11 time: 6.49\n",
            "[7,   200] loss: 0.847 acc: 65.26 time: 6.90\n",
            "[7,   300] loss: 0.823 acc: 65.94 time: 7.17\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 66.97 %\n",
            "Average loss on the 10000 test images: 0.815\n",
            "[8,   100] loss: 0.827 acc: 66.34 time: 6.60\n",
            "[8,   200] loss: 0.823 acc: 66.41 time: 6.92\n",
            "[8,   300] loss: 0.822 acc: 66.65 time: 7.16\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 66.99 %\n",
            "Average loss on the 10000 test images: 0.810\n",
            "[9,   100] loss: 0.817 acc: 66.62 time: 6.79\n",
            "[9,   200] loss: 0.792 acc: 67.32 time: 7.03\n",
            "[9,   300] loss: 0.798 acc: 67.69 time: 6.86\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 69.29 %\n",
            "Average loss on the 10000 test images: 0.755\n",
            "[10,   100] loss: 0.795 acc: 67.56 time: 6.63\n",
            "[10,   200] loss: 0.787 acc: 67.86 time: 7.03\n",
            "[10,   300] loss: 0.764 acc: 69.41 time: 6.81\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 69.68 %\n",
            "Average loss on the 10000 test images: 0.752\n",
            "[11,   100] loss: 0.757 acc: 69.28 time: 6.40\n",
            "[11,   200] loss: 0.751 acc: 69.78 time: 6.81\n",
            "[11,   300] loss: 0.760 acc: 69.62 time: 7.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 69.79 %\n",
            "Average loss on the 10000 test images: 0.739\n",
            "[12,   100] loss: 0.747 acc: 70.37 time: 6.78\n",
            "[12,   200] loss: 0.750 acc: 69.99 time: 6.92\n",
            "[12,   300] loss: 0.743 acc: 70.12 time: 7.26\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.46 %\n",
            "Average loss on the 10000 test images: 0.724\n",
            "[13,   100] loss: 0.731 acc: 70.88 time: 6.85\n",
            "[13,   200] loss: 0.728 acc: 70.46 time: 6.77\n",
            "[13,   300] loss: 0.716 acc: 71.45 time: 6.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.85 %\n",
            "Average loss on the 10000 test images: 0.710\n",
            "[14,   100] loss: 0.716 acc: 71.20 time: 6.87\n",
            "[14,   200] loss: 0.709 acc: 71.94 time: 6.92\n",
            "[14,   300] loss: 0.712 acc: 71.39 time: 6.49\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.40 %\n",
            "Average loss on the 10000 test images: 0.698\n",
            "[15,   100] loss: 0.700 acc: 72.43 time: 6.86\n",
            "[15,   200] loss: 0.689 acc: 72.38 time: 6.91\n",
            "[15,   300] loss: 0.685 acc: 72.81 time: 6.98\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.72 %\n",
            "Average loss on the 10000 test images: 0.686\n",
            "[16,   100] loss: 0.672 acc: 73.34 time: 7.06\n",
            "[16,   200] loss: 0.624 acc: 75.57 time: 6.71\n",
            "[16,   300] loss: 0.618 acc: 76.16 time: 6.78\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.93 %\n",
            "Average loss on the 10000 test images: 0.622\n",
            "[17,   100] loss: 0.613 acc: 75.87 time: 6.52\n",
            "[17,   200] loss: 0.601 acc: 76.14 time: 6.99\n",
            "[17,   300] loss: 0.608 acc: 76.51 time: 6.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.68 %\n",
            "Average loss on the 10000 test images: 0.612\n",
            "[18,   100] loss: 0.606 acc: 75.73 time: 6.77\n",
            "[18,   200] loss: 0.601 acc: 76.63 time: 6.77\n",
            "[18,   300] loss: 0.602 acc: 76.51 time: 7.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 75.81 %\n",
            "Average loss on the 10000 test images: 0.614\n",
            "[19,   100] loss: 0.598 acc: 76.31 time: 7.03\n",
            "[19,   200] loss: 0.589 acc: 76.59 time: 6.69\n",
            "[19,   300] loss: 0.597 acc: 76.46 time: 7.13\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.41 %\n",
            "Average loss on the 10000 test images: 0.598\n",
            "[20,   100] loss: 0.600 acc: 76.45 time: 6.66\n",
            "[20,   200] loss: 0.595 acc: 76.41 time: 6.69\n",
            "[20,   300] loss: 0.585 acc: 77.20 time: 6.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.41 %\n",
            "Average loss on the 10000 test images: 0.598\n",
            "[21,   100] loss: 0.587 acc: 77.18 time: 6.91\n",
            "[21,   200] loss: 0.581 acc: 77.41 time: 6.94\n",
            "[21,   300] loss: 0.590 acc: 76.82 time: 6.67\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.29 %\n",
            "Average loss on the 10000 test images: 0.594\n",
            "[22,   100] loss: 0.582 acc: 77.41 time: 7.08\n",
            "[22,   200] loss: 0.596 acc: 76.69 time: 6.62\n",
            "[22,   300] loss: 0.581 acc: 77.14 time: 6.51\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.82 %\n",
            "Average loss on the 10000 test images: 0.587\n",
            "[23,   100] loss: 0.597 acc: 76.62 time: 6.58\n",
            "[23,   200] loss: 0.575 acc: 77.39 time: 6.81\n",
            "[23,   300] loss: 0.563 acc: 78.23 time: 6.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.03 %\n",
            "Average loss on the 10000 test images: 0.587\n",
            "[24,   100] loss: 0.580 acc: 77.31 time: 6.58\n",
            "[24,   200] loss: 0.581 acc: 77.19 time: 6.56\n",
            "[24,   300] loss: 0.572 acc: 77.56 time: 6.53\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.98 %\n",
            "Average loss on the 10000 test images: 0.581\n",
            "[25,   100] loss: 0.576 acc: 77.30 time: 6.63\n",
            "[25,   200] loss: 0.559 acc: 78.24 time: 6.76\n",
            "[25,   300] loss: 0.573 acc: 77.84 time: 6.77\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.49 %\n",
            "Average loss on the 10000 test images: 0.580\n",
            "[26,   100] loss: 0.575 acc: 77.76 time: 6.93\n",
            "[26,   200] loss: 0.557 acc: 78.19 time: 6.81\n",
            "[26,   300] loss: 0.562 acc: 77.71 time: 6.89\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.26 %\n",
            "Average loss on the 10000 test images: 0.580\n",
            "[27,   100] loss: 0.569 acc: 77.77 time: 7.28\n",
            "[27,   200] loss: 0.555 acc: 78.45 time: 7.00\n",
            "[27,   300] loss: 0.569 acc: 77.61 time: 7.03\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.45 %\n",
            "Average loss on the 10000 test images: 0.580\n",
            "[28,   100] loss: 0.573 acc: 77.45 time: 6.98\n",
            "[28,   200] loss: 0.561 acc: 77.92 time: 6.84\n",
            "[28,   300] loss: 0.544 acc: 79.04 time: 6.96\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.75 %\n",
            "Average loss on the 10000 test images: 0.590\n",
            "[29,   100] loss: 0.569 acc: 77.85 time: 6.79\n",
            "[29,   200] loss: 0.554 acc: 78.31 time: 6.74\n",
            "[29,   300] loss: 0.556 acc: 78.25 time: 6.79\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.81 %\n",
            "Average loss on the 10000 test images: 0.563\n",
            "[30,   100] loss: 0.552 acc: 78.48 time: 6.61\n",
            "[30,   200] loss: 0.548 acc: 78.64 time: 6.83\n",
            "[30,   300] loss: 0.559 acc: 77.91 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.62 %\n",
            "Average loss on the 10000 test images: 0.574\n",
            "[31,   100] loss: 0.549 acc: 78.59 time: 6.71\n",
            "[31,   200] loss: 0.538 acc: 78.83 time: 6.63\n",
            "[31,   300] loss: 0.547 acc: 78.62 time: 6.91\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.24 %\n",
            "Average loss on the 10000 test images: 0.569\n",
            "[32,   100] loss: 0.543 acc: 78.77 time: 6.73\n",
            "[32,   200] loss: 0.541 acc: 78.64 time: 7.04\n",
            "[32,   300] loss: 0.549 acc: 78.11 time: 6.91\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.93 %\n",
            "Average loss on the 10000 test images: 0.564\n",
            "[33,   100] loss: 0.545 acc: 78.62 time: 6.51\n",
            "[33,   200] loss: 0.527 acc: 79.69 time: 6.92\n",
            "[33,   300] loss: 0.551 acc: 78.41 time: 6.56\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.58 %\n",
            "Average loss on the 10000 test images: 0.570\n",
            "[34,   100] loss: 0.553 acc: 79.03 time: 6.67\n",
            "[34,   200] loss: 0.536 acc: 79.05 time: 6.85\n",
            "[34,   300] loss: 0.550 acc: 78.69 time: 6.92\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.70 %\n",
            "Average loss on the 10000 test images: 0.566\n",
            "[35,   100] loss: 0.535 acc: 79.23 time: 6.68\n",
            "[35,   200] loss: 0.549 acc: 78.59 time: 6.70\n",
            "[35,   300] loss: 0.552 acc: 78.34 time: 6.81\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.12 %\n",
            "Average loss on the 10000 test images: 0.562\n",
            "[36,   100] loss: 0.540 acc: 78.92 time: 6.44\n",
            "[36,   200] loss: 0.548 acc: 78.51 time: 6.94\n",
            "[36,   300] loss: 0.542 acc: 78.62 time: 7.10\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.95 %\n",
            "Average loss on the 10000 test images: 0.556\n",
            "[37,   100] loss: 0.546 acc: 78.68 time: 6.46\n",
            "[37,   200] loss: 0.543 acc: 78.89 time: 6.81\n",
            "[37,   300] loss: 0.542 acc: 78.81 time: 7.12\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.22 %\n",
            "Average loss on the 10000 test images: 0.558\n",
            "[38,   100] loss: 0.544 acc: 78.34 time: 6.71\n",
            "[38,   200] loss: 0.548 acc: 78.51 time: 6.69\n",
            "[38,   300] loss: 0.532 acc: 79.29 time: 6.95\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.09 %\n",
            "Average loss on the 10000 test images: 0.563\n",
            "[39,   100] loss: 0.540 acc: 78.96 time: 6.39\n",
            "[39,   200] loss: 0.539 acc: 78.97 time: 6.93\n",
            "[39,   300] loss: 0.537 acc: 79.38 time: 6.82\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.02 %\n",
            "Average loss on the 10000 test images: 0.561\n",
            "[40,   100] loss: 0.541 acc: 79.29 time: 7.11\n",
            "[40,   200] loss: 0.544 acc: 78.74 time: 6.90\n",
            "[40,   300] loss: 0.543 acc: 78.62 time: 6.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.38 %\n",
            "Average loss on the 10000 test images: 0.562\n",
            "[41,   100] loss: 0.537 acc: 79.09 time: 6.68\n",
            "[41,   200] loss: 0.529 acc: 79.27 time: 6.87\n",
            "[41,   300] loss: 0.540 acc: 78.89 time: 7.22\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.21 %\n",
            "Average loss on the 10000 test images: 0.563\n",
            "[42,   100] loss: 0.535 acc: 79.02 time: 6.69\n",
            "[42,   200] loss: 0.560 acc: 77.89 time: 6.99\n",
            "[42,   300] loss: 0.525 acc: 79.72 time: 7.18\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.08 %\n",
            "Average loss on the 10000 test images: 0.563\n",
            "[43,   100] loss: 0.532 acc: 79.41 time: 6.57\n",
            "[43,   200] loss: 0.545 acc: 78.94 time: 6.77\n",
            "[43,   300] loss: 0.535 acc: 79.05 time: 7.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.90 %\n",
            "Average loss on the 10000 test images: 0.560\n",
            "[44,   100] loss: 0.537 acc: 79.22 time: 6.58\n",
            "[44,   200] loss: 0.536 acc: 79.27 time: 6.79\n",
            "[44,   300] loss: 0.535 acc: 79.17 time: 7.10\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.06 %\n",
            "Average loss on the 10000 test images: 0.561\n",
            "[45,   100] loss: 0.537 acc: 79.30 time: 6.94\n",
            "[45,   200] loss: 0.533 acc: 79.28 time: 6.95\n",
            "[45,   300] loss: 0.541 acc: 78.96 time: 7.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.60 %\n",
            "Average loss on the 10000 test images: 0.559\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.001, task='rotation')\n",
        "################################\n",
        "#     TODO: Save the model     #\n",
        "################################\n",
        "#torch.save(net.state_dict(), 'TRAINING.pt')\n",
        "################################\n",
        "#      End of your code        #\n",
        "################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net, 'B094020030_rot_mdl.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLMRTS9rTnk"
      },
      "source": [
        "## Fine-tuning on the pre-trained model (9 points)\n",
        "\n",
        "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
        "\n",
        "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "S4nX4ExlrymI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from sympy import true\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "#####################################################\n",
        "#     TODO: Load the pre-trained ResNet18 model     #\n",
        "#####################################################\n",
        "net = torch.load('B094020030_rot_mdl.pt')\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "####################################################\n",
        "#                End of your code                  #\n",
        "####################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "kD44g-TxwYdU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#################################################################################################\n",
        "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n",
        "#################################################################################################\n",
        "# 先凍結所有層\n",
        "for params in net.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "# layer4 與 fc layer 依然可以更新權重\n",
        "for params in net.layer4.parameters():\n",
        "    params.requires_grad = True\n",
        "for params in net.fc.parameters():\n",
        "    params.requires_grad = True\n",
        "    \n",
        "# 修改FC layer架構\n",
        "net.fc = nn.Linear(net.fc.in_features, 10) # 輸出10類別\n",
        "net.to(device)\n",
        "\n",
        "#################################################################################################\n",
        "#                                          End of your code                                     #\n",
        "#################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "9T5DX0efr4fh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t layer4.0.conv1.weight\n",
            "\t layer4.0.bn1.weight\n",
            "\t layer4.0.bn1.bias\n",
            "\t layer4.0.conv2.weight\n",
            "\t layer4.0.bn2.weight\n",
            "\t layer4.0.bn2.bias\n",
            "\t layer4.0.downsample.0.weight\n",
            "\t layer4.0.downsample.1.weight\n",
            "\t layer4.0.downsample.1.bias\n",
            "\t layer4.1.conv1.weight\n",
            "\t layer4.1.bn1.weight\n",
            "\t layer4.1.bn1.bias\n",
            "\t layer4.1.conv2.weight\n",
            "\t layer4.1.bn2.weight\n",
            "\t layer4.1.bn2.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Print all the trainable parameters\n",
        "params_to_update = net.parameters()\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "xb032dG700ph"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "# Note that your optimizer only needs to update the parameters that are trainable.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam([\n",
        "    {'params': net.layer4.parameters()},\n",
        "    {'params': net.fc.parameters()}\n",
        "], lr=0.001)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "3vLSwOo6sBjl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.639 acc: 40.77 time: 6.17\n",
            "[1,   200] loss: 1.379 acc: 49.68 time: 6.56\n",
            "[1,   300] loss: 1.305 acc: 52.58 time: 6.66\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 55.96 %\n",
            "Average loss on the 10000 test images: 1.231\n",
            "[2,   100] loss: 1.227 acc: 55.88 time: 6.49\n",
            "[2,   200] loss: 1.222 acc: 55.89 time: 6.55\n",
            "[2,   300] loss: 1.209 acc: 56.29 time: 6.75\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 57.65 %\n",
            "Average loss on the 10000 test images: 1.176\n",
            "[3,   100] loss: 1.181 acc: 57.16 time: 6.44\n",
            "[3,   200] loss: 1.160 acc: 58.10 time: 6.63\n",
            "[3,   300] loss: 1.149 acc: 57.88 time: 6.93\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 59.25 %\n",
            "Average loss on the 10000 test images: 1.134\n",
            "[4,   100] loss: 1.117 acc: 59.50 time: 6.44\n",
            "[4,   200] loss: 1.145 acc: 58.77 time: 6.63\n",
            "[4,   300] loss: 1.130 acc: 58.95 time: 6.86\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 60.26 %\n",
            "Average loss on the 10000 test images: 1.117\n",
            "[5,   100] loss: 1.095 acc: 60.20 time: 6.62\n",
            "[5,   200] loss: 1.097 acc: 60.33 time: 6.31\n",
            "[5,   300] loss: 1.106 acc: 59.91 time: 6.45\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.19 %\n",
            "Average loss on the 10000 test images: 1.096\n",
            "[6,   100] loss: 1.084 acc: 60.95 time: 6.61\n",
            "[6,   200] loss: 1.087 acc: 60.90 time: 6.48\n",
            "[6,   300] loss: 1.081 acc: 60.90 time: 6.74\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.16 %\n",
            "Average loss on the 10000 test images: 1.084\n",
            "[7,   100] loss: 1.050 acc: 62.05 time: 6.55\n",
            "[7,   200] loss: 1.053 acc: 62.30 time: 6.39\n",
            "[7,   300] loss: 1.087 acc: 61.30 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.56 %\n",
            "Average loss on the 10000 test images: 1.070\n",
            "[8,   100] loss: 1.034 acc: 62.53 time: 6.49\n",
            "[8,   200] loss: 1.047 acc: 62.55 time: 6.42\n",
            "[8,   300] loss: 1.053 acc: 61.93 time: 7.14\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.10 %\n",
            "Average loss on the 10000 test images: 1.056\n",
            "[9,   100] loss: 1.035 acc: 63.59 time: 6.56\n",
            "[9,   200] loss: 1.024 acc: 63.16 time: 6.36\n",
            "[9,   300] loss: 1.020 acc: 62.46 time: 6.92\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.56 %\n",
            "Average loss on the 10000 test images: 1.044\n",
            "[10,   100] loss: 1.013 acc: 63.13 time: 6.45\n",
            "[10,   200] loss: 1.012 acc: 63.45 time: 6.41\n",
            "[10,   300] loss: 1.023 acc: 63.02 time: 6.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 62.67 %\n",
            "Average loss on the 10000 test images: 1.054\n",
            "[11,   100] loss: 0.993 acc: 64.29 time: 6.55\n",
            "[11,   200] loss: 0.994 acc: 63.86 time: 6.61\n",
            "[11,   300] loss: 1.004 acc: 63.68 time: 7.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.35 %\n",
            "Average loss on the 10000 test images: 1.030\n",
            "[12,   100] loss: 0.995 acc: 64.72 time: 6.50\n",
            "[12,   200] loss: 1.000 acc: 63.53 time: 6.59\n",
            "[12,   300] loss: 0.985 acc: 64.69 time: 6.97\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.04 %\n",
            "Average loss on the 10000 test images: 1.035\n",
            "[13,   100] loss: 0.971 acc: 64.88 time: 6.53\n",
            "[13,   200] loss: 0.999 acc: 63.59 time: 6.44\n",
            "[13,   300] loss: 0.977 acc: 65.13 time: 6.97\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.08 %\n",
            "Average loss on the 10000 test images: 1.018\n",
            "[14,   100] loss: 0.976 acc: 64.76 time: 6.50\n",
            "[14,   200] loss: 0.973 acc: 65.14 time: 6.45\n",
            "[14,   300] loss: 0.970 acc: 64.96 time: 6.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.91 %\n",
            "Average loss on the 10000 test images: 1.014\n",
            "[15,   100] loss: 0.951 acc: 65.30 time: 6.54\n",
            "[15,   200] loss: 0.969 acc: 65.38 time: 6.43\n",
            "[15,   300] loss: 0.968 acc: 64.87 time: 6.98\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.57 %\n",
            "Average loss on the 10000 test images: 1.026\n",
            "[16,   100] loss: 0.944 acc: 66.29 time: 6.70\n",
            "[16,   200] loss: 0.968 acc: 65.25 time: 6.40\n",
            "[16,   300] loss: 0.966 acc: 65.29 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.75 %\n",
            "Average loss on the 10000 test images: 1.001\n",
            "[17,   100] loss: 0.932 acc: 66.14 time: 6.60\n",
            "[17,   200] loss: 0.942 acc: 65.91 time: 6.38\n",
            "[17,   300] loss: 0.941 acc: 65.64 time: 6.96\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.51 %\n",
            "Average loss on the 10000 test images: 1.022\n",
            "[18,   100] loss: 0.939 acc: 66.84 time: 6.43\n",
            "[18,   200] loss: 0.947 acc: 66.19 time: 6.41\n",
            "[18,   300] loss: 0.942 acc: 66.16 time: 7.11\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.17 %\n",
            "Average loss on the 10000 test images: 1.019\n",
            "[19,   100] loss: 0.913 acc: 67.24 time: 6.44\n",
            "[19,   200] loss: 0.940 acc: 66.19 time: 6.35\n",
            "[19,   300] loss: 0.939 acc: 66.67 time: 7.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.75 %\n",
            "Average loss on the 10000 test images: 1.001\n",
            "[20,   100] loss: 0.920 acc: 66.70 time: 6.47\n",
            "[20,   200] loss: 0.928 acc: 66.96 time: 6.38\n",
            "[20,   300] loss: 0.931 acc: 66.42 time: 6.99\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.07 %\n",
            "Average loss on the 10000 test images: 1.023\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=20, init_lr=0.001, task='classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'FINETUNED_w.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPNhcJBrcNj"
      },
      "source": [
        "## Fine-tuning on the randomly initialized model (9 points)\n",
        "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "2RfXAh9vxXRB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "#################################################\n",
        "# TODO: Randomly initialize a ResNet18 model    #\n",
        "#################################################\n",
        "net = resnet18(weights=None, num_classes=4) # 定義模型架構，no pre-trained wieght\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correctprint(net) # print your model and check the num_classes is correct\n",
        "#################################################\n",
        "#              End of your code                 #\n",
        "#################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "fpx-SYAizt4p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#################################################################################################\n",
        "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
        "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
        "#################################################################################################\n",
        "for params in net.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "for params in net.layer4.parameters():\n",
        "    params.requires_grad = True\n",
        "for params in net.fc.parameters():\n",
        "    params.requires_grad = True\n",
        "    \n",
        "net.fc = nn.Linear(net.fc.in_features, 10) # 10 classes\n",
        "net.to(device)\n",
        "print(net)\n",
        "#################################################################################################\n",
        "#                                          End of your code                                     #\n",
        "#################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "BUFWizbHxgm2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t layer4.0.conv1.weight\n",
            "\t layer4.0.bn1.weight\n",
            "\t layer4.0.bn1.bias\n",
            "\t layer4.0.conv2.weight\n",
            "\t layer4.0.bn2.weight\n",
            "\t layer4.0.bn2.bias\n",
            "\t layer4.0.downsample.0.weight\n",
            "\t layer4.0.downsample.1.weight\n",
            "\t layer4.0.downsample.1.bias\n",
            "\t layer4.1.conv1.weight\n",
            "\t layer4.1.bn1.weight\n",
            "\t layer4.1.bn1.bias\n",
            "\t layer4.1.conv2.weight\n",
            "\t layer4.1.bn2.weight\n",
            "\t layer4.1.bn2.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Print all the trainable parameters\n",
        "params_to_update = net.parameters()\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "BxFrGj091AN_"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "# Note that your optimizer only needs to update the parameters that are trainable.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=[\n",
        "    {'params': net.layer4.parameters()},\n",
        "    {'params': net.fc.parameters()}],\n",
        "                       lr=0.001)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "GzRVy0MZxpoL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.037 acc: 26.94 time: 6.40\n",
            "[1,   200] loss: 1.876 acc: 31.34 time: 6.30\n",
            "[1,   300] loss: 1.840 acc: 33.59 time: 6.85\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 37.07 %\n",
            "Average loss on the 10000 test images: 1.735\n",
            "[2,   100] loss: 1.795 acc: 35.33 time: 6.57\n",
            "[2,   200] loss: 1.776 acc: 35.18 time: 6.39\n",
            "[2,   300] loss: 1.759 acc: 35.66 time: 7.01\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 40.29 %\n",
            "Average loss on the 10000 test images: 1.665\n",
            "[3,   100] loss: 1.733 acc: 37.01 time: 6.58\n",
            "[3,   200] loss: 1.727 acc: 37.68 time: 6.26\n",
            "[3,   300] loss: 1.738 acc: 36.58 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 40.64 %\n",
            "Average loss on the 10000 test images: 1.664\n",
            "[4,   100] loss: 1.694 acc: 38.81 time: 6.65\n",
            "[4,   200] loss: 1.725 acc: 37.46 time: 6.30\n",
            "[4,   300] loss: 1.708 acc: 37.58 time: 6.95\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 40.54 %\n",
            "Average loss on the 10000 test images: 1.643\n",
            "[5,   100] loss: 1.689 acc: 38.89 time: 6.67\n",
            "[5,   200] loss: 1.684 acc: 39.30 time: 6.26\n",
            "[5,   300] loss: 1.685 acc: 39.07 time: 6.98\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.47 %\n",
            "Average loss on the 10000 test images: 1.624\n",
            "[6,   100] loss: 1.656 acc: 40.19 time: 6.61\n",
            "[6,   200] loss: 1.665 acc: 40.05 time: 6.32\n",
            "[6,   300] loss: 1.664 acc: 39.63 time: 7.07\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.95 %\n",
            "Average loss on the 10000 test images: 1.618\n",
            "[7,   100] loss: 1.650 acc: 40.43 time: 6.64\n",
            "[7,   200] loss: 1.640 acc: 40.19 time: 6.42\n",
            "[7,   300] loss: 1.650 acc: 40.37 time: 6.97\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 42.06 %\n",
            "Average loss on the 10000 test images: 1.610\n",
            "[8,   100] loss: 1.622 acc: 41.27 time: 6.60\n",
            "[8,   200] loss: 1.633 acc: 40.82 time: 6.30\n",
            "[8,   300] loss: 1.638 acc: 41.29 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 41.95 %\n",
            "Average loss on the 10000 test images: 1.612\n",
            "[9,   100] loss: 1.621 acc: 41.36 time: 6.59\n",
            "[9,   200] loss: 1.641 acc: 40.94 time: 6.36\n",
            "[9,   300] loss: 1.614 acc: 41.95 time: 6.94\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.57 %\n",
            "Average loss on the 10000 test images: 1.582\n",
            "[10,   100] loss: 1.625 acc: 41.27 time: 6.55\n",
            "[10,   200] loss: 1.623 acc: 41.34 time: 6.35\n",
            "[10,   300] loss: 1.623 acc: 41.50 time: 6.97\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.37 %\n",
            "Average loss on the 10000 test images: 1.590\n",
            "[11,   100] loss: 1.589 acc: 43.30 time: 6.67\n",
            "[11,   200] loss: 1.581 acc: 43.98 time: 6.37\n",
            "[11,   300] loss: 1.572 acc: 43.66 time: 7.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.35 %\n",
            "Average loss on the 10000 test images: 1.558\n",
            "[12,   100] loss: 1.568 acc: 44.05 time: 6.86\n",
            "[12,   200] loss: 1.568 acc: 43.66 time: 6.31\n",
            "[12,   300] loss: 1.554 acc: 44.14 time: 6.97\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 44.98 %\n",
            "Average loss on the 10000 test images: 1.546\n",
            "[13,   100] loss: 1.554 acc: 44.31 time: 6.58\n",
            "[13,   200] loss: 1.554 acc: 44.11 time: 6.33\n",
            "[13,   300] loss: 1.561 acc: 44.03 time: 7.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.02 %\n",
            "Average loss on the 10000 test images: 1.540\n",
            "[14,   100] loss: 1.547 acc: 44.85 time: 6.68\n",
            "[14,   200] loss: 1.553 acc: 44.34 time: 6.23\n",
            "[14,   300] loss: 1.554 acc: 44.60 time: 7.03\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.23 %\n",
            "Average loss on the 10000 test images: 1.537\n",
            "[15,   100] loss: 1.557 acc: 44.30 time: 6.80\n",
            "[15,   200] loss: 1.542 acc: 44.85 time: 6.17\n",
            "[15,   300] loss: 1.542 acc: 44.27 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.28 %\n",
            "Average loss on the 10000 test images: 1.535\n",
            "[16,   100] loss: 1.533 acc: 44.91 time: 6.76\n",
            "[16,   200] loss: 1.532 acc: 45.69 time: 6.84\n",
            "[16,   300] loss: 1.539 acc: 45.12 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.54 %\n",
            "Average loss on the 10000 test images: 1.533\n",
            "[17,   100] loss: 1.530 acc: 44.97 time: 6.61\n",
            "[17,   200] loss: 1.520 acc: 45.24 time: 6.31\n",
            "[17,   300] loss: 1.543 acc: 44.69 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.39 %\n",
            "Average loss on the 10000 test images: 1.534\n",
            "[18,   100] loss: 1.546 acc: 44.64 time: 6.56\n",
            "[18,   200] loss: 1.540 acc: 45.39 time: 6.40\n",
            "[18,   300] loss: 1.517 acc: 45.75 time: 7.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.72 %\n",
            "Average loss on the 10000 test images: 1.532\n",
            "[19,   100] loss: 1.539 acc: 44.33 time: 6.53\n",
            "[19,   200] loss: 1.517 acc: 45.23 time: 6.46\n",
            "[19,   300] loss: 1.532 acc: 45.12 time: 7.00\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.99 %\n",
            "Average loss on the 10000 test images: 1.527\n",
            "[20,   100] loss: 1.518 acc: 45.39 time: 6.62\n",
            "[20,   200] loss: 1.524 acc: 44.91 time: 6.50\n",
            "[20,   300] loss: 1.528 acc: 45.55 time: 7.03\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 45.89 %\n",
            "Average loss on the 10000 test images: 1.525\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.001, task='classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'FINETUNED_rand.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcN54tcNN15U"
      },
      "source": [
        "## Supervised training on the pre-trained model (9 points)\n",
        "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
        "\n",
        "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "9xR9h_S1N6Xi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "#####################################################\n",
        "#     TODO: Load the pre-trained ResNet18 model     #\n",
        "#####################################################\n",
        "net = torch.load(\"B094020030_rot_mdl.pt\")\n",
        "net.fc = nn.Linear(net.fc.in_features, 10) # 10 classes\n",
        "net = net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "#####################################################\n",
        "#                End of your code                   #\n",
        "#####################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "gGozc2cM0ADw"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=net.parameters(),lr = 0.01)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = torch.load(\"RETRAINED_w.pth\")\n",
        "net.load_state_dict(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "JGWW7gzCz_Bu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.576 acc: 41.07 time: 6.34\n",
            "[1,   200] loss: 1.212 acc: 56.27 time: 6.72\n",
            "[1,   300] loss: 1.101 acc: 60.99 time: 6.86\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 63.65 %\n",
            "Average loss on the 10000 test images: 1.034\n",
            "[2,   100] loss: 1.000 acc: 64.34 time: 6.43\n",
            "[2,   200] loss: 0.931 acc: 67.43 time: 6.71\n",
            "[2,   300] loss: 0.902 acc: 68.11 time: 6.65\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 67.53 %\n",
            "Average loss on the 10000 test images: 0.931\n",
            "[3,   100] loss: 0.855 acc: 70.34 time: 6.47\n",
            "[3,   200] loss: 0.845 acc: 70.48 time: 6.51\n",
            "[3,   300] loss: 0.826 acc: 71.20 time: 7.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 72.21 %\n",
            "Average loss on the 10000 test images: 0.794\n",
            "[4,   100] loss: 0.767 acc: 73.42 time: 6.73\n",
            "[4,   200] loss: 0.757 acc: 73.59 time: 6.83\n",
            "[4,   300] loss: 0.755 acc: 73.61 time: 6.93\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 73.58 %\n",
            "Average loss on the 10000 test images: 0.769\n",
            "[5,   100] loss: 0.715 acc: 75.17 time: 6.50\n",
            "[5,   200] loss: 0.707 acc: 74.99 time: 6.56\n",
            "[5,   300] loss: 0.706 acc: 75.39 time: 6.65\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.12 %\n",
            "Average loss on the 10000 test images: 0.761\n",
            "[6,   100] loss: 0.658 acc: 77.25 time: 6.72\n",
            "[6,   200] loss: 0.663 acc: 76.49 time: 6.60\n",
            "[6,   300] loss: 0.668 acc: 76.84 time: 6.90\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.62 %\n",
            "Average loss on the 10000 test images: 0.682\n",
            "[7,   100] loss: 0.621 acc: 78.45 time: 6.69\n",
            "[7,   200] loss: 0.624 acc: 78.33 time: 6.78\n",
            "[7,   300] loss: 0.642 acc: 77.94 time: 7.12\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 77.01 %\n",
            "Average loss on the 10000 test images: 0.670\n",
            "[8,   100] loss: 0.607 acc: 78.88 time: 6.41\n",
            "[8,   200] loss: 0.607 acc: 78.64 time: 6.83\n",
            "[8,   300] loss: 0.613 acc: 79.12 time: 6.77\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.98 %\n",
            "Average loss on the 10000 test images: 0.670\n",
            "[9,   100] loss: 0.564 acc: 80.40 time: 6.59\n",
            "[9,   200] loss: 0.580 acc: 80.09 time: 6.54\n",
            "[9,   300] loss: 0.587 acc: 79.83 time: 6.84\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 76.82 %\n",
            "Average loss on the 10000 test images: 0.688\n",
            "[10,   100] loss: 0.555 acc: 80.83 time: 6.88\n",
            "[10,   200] loss: 0.544 acc: 81.19 time: 6.71\n",
            "[10,   300] loss: 0.555 acc: 80.90 time: 6.85\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.66 %\n",
            "Average loss on the 10000 test images: 0.623\n",
            "[11,   100] loss: 0.466 acc: 83.62 time: 6.62\n",
            "[11,   200] loss: 0.449 acc: 84.49 time: 6.83\n",
            "[11,   300] loss: 0.443 acc: 84.62 time: 6.95\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.49 %\n",
            "Average loss on the 10000 test images: 0.567\n",
            "[12,   100] loss: 0.435 acc: 85.36 time: 6.20\n",
            "[12,   200] loss: 0.411 acc: 85.56 time: 6.87\n",
            "[12,   300] loss: 0.423 acc: 85.05 time: 7.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.45 %\n",
            "Average loss on the 10000 test images: 0.572\n",
            "[13,   100] loss: 0.403 acc: 85.76 time: 6.52\n",
            "[13,   200] loss: 0.422 acc: 85.28 time: 6.76\n",
            "[13,   300] loss: 0.403 acc: 86.04 time: 7.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.51 %\n",
            "Average loss on the 10000 test images: 0.571\n",
            "[14,   100] loss: 0.404 acc: 86.15 time: 6.31\n",
            "[14,   200] loss: 0.410 acc: 85.79 time: 6.87\n",
            "[14,   300] loss: 0.399 acc: 86.22 time: 7.08\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.96 %\n",
            "Average loss on the 10000 test images: 0.562\n",
            "[15,   100] loss: 0.394 acc: 86.46 time: 6.66\n",
            "[15,   200] loss: 0.390 acc: 86.36 time: 6.79\n",
            "[15,   300] loss: 0.392 acc: 86.56 time: 7.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.46 %\n",
            "Average loss on the 10000 test images: 0.550\n",
            "[16,   100] loss: 0.379 acc: 86.90 time: 6.53\n",
            "[16,   200] loss: 0.386 acc: 86.77 time: 6.76\n",
            "[16,   300] loss: 0.395 acc: 86.27 time: 7.06\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.22 %\n",
            "Average loss on the 10000 test images: 0.563\n",
            "[17,   100] loss: 0.383 acc: 86.94 time: 6.60\n",
            "[17,   200] loss: 0.373 acc: 86.98 time: 6.81\n",
            "[17,   300] loss: 0.374 acc: 87.05 time: 7.17\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.47 %\n",
            "Average loss on the 10000 test images: 0.555\n",
            "[18,   100] loss: 0.364 acc: 87.58 time: 6.57\n",
            "[18,   200] loss: 0.370 acc: 87.18 time: 6.77\n",
            "[18,   300] loss: 0.373 acc: 87.12 time: 7.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.27 %\n",
            "Average loss on the 10000 test images: 0.551\n",
            "[19,   100] loss: 0.372 acc: 86.88 time: 6.55\n",
            "[19,   200] loss: 0.362 acc: 87.55 time: 6.72\n",
            "[19,   300] loss: 0.371 acc: 86.81 time: 7.03\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.28 %\n",
            "Average loss on the 10000 test images: 0.553\n",
            "[20,   100] loss: 0.359 acc: 87.73 time: 6.57\n",
            "[20,   200] loss: 0.356 acc: 87.62 time: 6.72\n",
            "[20,   300] loss: 0.365 acc: 87.61 time: 7.09\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 81.15 %\n",
            "Average loss on the 10000 test images: 0.550\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'RETRAINED_w.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjVTp9jhefTi"
      },
      "source": [
        "## Supervised training on the randomly initialized model (9 points)\n",
        "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "uEjy8TBieeLK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "#################################################\n",
        "# TODO: Randomly initialize a ResNet18 model    #\n",
        "#################################################\n",
        "net = resnet18(weights=None)\n",
        "net.fc = nn.Linear(net.fc.in_features, 10)\n",
        "\n",
        "net.to(device)\n",
        "print(net) # print your model and check the num_classes is correct\n",
        "#################################################\n",
        "#              End of your code                 #\n",
        "#################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "jEY90pK_0ZAm"
      },
      "outputs": [],
      "source": [
        "# TODO: Define criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=net.parameters(),lr=0.01)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "lMDwelhY0auO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.320 acc: 19.63 time: 6.68\n",
            "[1,   200] loss: 1.896 acc: 31.17 time: 6.72\n",
            "[1,   300] loss: 1.760 acc: 34.65 time: 6.95\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 43.24 %\n",
            "Average loss on the 10000 test images: 1.541\n",
            "[2,   100] loss: 1.584 acc: 41.49 time: 6.94\n",
            "[2,   200] loss: 1.499 acc: 45.49 time: 6.79\n",
            "[2,   300] loss: 1.452 acc: 46.80 time: 6.28\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 49.02 %\n",
            "Average loss on the 10000 test images: 1.373\n",
            "[3,   100] loss: 1.319 acc: 51.61 time: 6.57\n",
            "[3,   200] loss: 1.263 acc: 54.35 time: 6.76\n",
            "[3,   300] loss: 1.207 acc: 56.52 time: 6.47\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 61.76 %\n",
            "Average loss on the 10000 test images: 1.088\n",
            "[4,   100] loss: 1.122 acc: 59.72 time: 6.67\n",
            "[4,   200] loss: 1.080 acc: 61.77 time: 6.76\n",
            "[4,   300] loss: 1.052 acc: 62.30 time: 6.36\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 64.74 %\n",
            "Average loss on the 10000 test images: 1.003\n",
            "[5,   100] loss: 1.007 acc: 64.51 time: 6.53\n",
            "[5,   200] loss: 0.968 acc: 65.34 time: 6.80\n",
            "[5,   300] loss: 0.967 acc: 66.00 time: 6.15\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 68.85 %\n",
            "Average loss on the 10000 test images: 0.912\n",
            "[6,   100] loss: 0.918 acc: 67.42 time: 6.44\n",
            "[6,   200] loss: 0.891 acc: 68.47 time: 6.62\n",
            "[6,   300] loss: 0.885 acc: 69.08 time: 6.88\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.11 %\n",
            "Average loss on the 10000 test images: 0.835\n",
            "[7,   100] loss: 0.835 acc: 70.54 time: 6.64\n",
            "[7,   200] loss: 0.825 acc: 71.23 time: 6.84\n",
            "[7,   300] loss: 0.829 acc: 70.38 time: 6.92\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 71.18 %\n",
            "Average loss on the 10000 test images: 0.836\n",
            "[8,   100] loss: 0.800 acc: 72.40 time: 6.59\n",
            "[8,   200] loss: 0.776 acc: 72.95 time: 6.72\n",
            "[8,   300] loss: 0.788 acc: 72.41 time: 7.05\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 73.02 %\n",
            "Average loss on the 10000 test images: 0.787\n",
            "[9,   100] loss: 0.739 acc: 74.66 time: 7.11\n",
            "[9,   200] loss: 0.729 acc: 74.73 time: 6.41\n",
            "[9,   300] loss: 0.736 acc: 74.23 time: 6.48\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.80 %\n",
            "Average loss on the 10000 test images: 0.728\n",
            "[10,   100] loss: 0.706 acc: 75.68 time: 5.91\n",
            "[10,   200] loss: 0.704 acc: 75.73 time: 6.51\n",
            "[10,   300] loss: 0.691 acc: 75.91 time: 7.29\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 74.40 %\n",
            "Average loss on the 10000 test images: 0.743\n",
            "[11,   100] loss: 0.608 acc: 79.06 time: 6.57\n",
            "[11,   200] loss: 0.577 acc: 80.04 time: 6.84\n",
            "[11,   300] loss: 0.576 acc: 79.76 time: 7.04\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 78.20 %\n",
            "Average loss on the 10000 test images: 0.637\n",
            "[12,   100] loss: 0.529 acc: 81.39 time: 7.04\n",
            "[12,   200] loss: 0.545 acc: 81.02 time: 7.03\n",
            "[12,   300] loss: 0.539 acc: 81.66 time: 6.75\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.04 %\n",
            "Average loss on the 10000 test images: 0.621\n",
            "[13,   100] loss: 0.517 acc: 81.72 time: 6.62\n",
            "[13,   200] loss: 0.527 acc: 81.44 time: 6.62\n",
            "[13,   300] loss: 0.509 acc: 82.05 time: 6.75\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.43 %\n",
            "Average loss on the 10000 test images: 0.618\n",
            "[14,   100] loss: 0.530 acc: 81.52 time: 6.37\n",
            "[14,   200] loss: 0.502 acc: 82.52 time: 6.42\n",
            "[14,   300] loss: 0.498 acc: 82.60 time: 7.07\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.00 %\n",
            "Average loss on the 10000 test images: 0.617\n",
            "[15,   100] loss: 0.476 acc: 83.38 time: 6.41\n",
            "[15,   200] loss: 0.491 acc: 82.71 time: 6.29\n",
            "[15,   300] loss: 0.509 acc: 82.50 time: 6.60\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.51 %\n",
            "Average loss on the 10000 test images: 0.605\n",
            "[16,   100] loss: 0.471 acc: 83.52 time: 6.66\n",
            "[16,   200] loss: 0.494 acc: 82.63 time: 6.87\n",
            "[16,   300] loss: 0.479 acc: 83.01 time: 6.91\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.75 %\n",
            "Average loss on the 10000 test images: 0.601\n",
            "[17,   100] loss: 0.471 acc: 83.34 time: 6.97\n",
            "[17,   200] loss: 0.461 acc: 83.91 time: 6.36\n",
            "[17,   300] loss: 0.470 acc: 83.43 time: 6.58\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.97 %\n",
            "Average loss on the 10000 test images: 0.605\n",
            "[18,   100] loss: 0.475 acc: 83.36 time: 6.63\n",
            "[18,   200] loss: 0.449 acc: 83.94 time: 6.67\n",
            "[18,   300] loss: 0.457 acc: 83.82 time: 6.90\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.04 %\n",
            "Average loss on the 10000 test images: 0.596\n",
            "[19,   100] loss: 0.444 acc: 84.50 time: 6.66\n",
            "[19,   200] loss: 0.451 acc: 84.32 time: 6.89\n",
            "[19,   300] loss: 0.449 acc: 84.30 time: 7.16\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 79.99 %\n",
            "Average loss on the 10000 test images: 0.600\n",
            "[20,   100] loss: 0.439 acc: 84.63 time: 6.52\n",
            "[20,   200] loss: 0.443 acc: 84.51 time: 6.77\n",
            "[20,   300] loss: 0.445 acc: 84.52 time: 7.02\n",
            "TESTING:\n",
            "Accuracy of the network on the 10000 test images: 80.51 %\n",
            "Average loss on the 10000 test images: 0.592\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'RETRAINED_rand.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn3-F_LdZkbC"
      },
      "source": [
        "# Write report (37 points)\n",
        "\n",
        "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫請大家根據以下要求完成，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
        "\n",
        "1. (13 points) Train a ResNet18 on the Rotation task and report the test performance. Discuss why such a task helps in learning features that are generalizable to other visual tasks.\n",
        "\n",
        "2. (12 points) Initializing from the Rotation model or from random weights, fine-tune only the weights of the final block of convolutional layers and linear layer on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights. You can also discuss how the performance of pre-trained models affects downstream tasks, the performance of fine-tuning different numbers of layers, and so on.\n",
        "\n",
        "3. (12 points) Initializing from the Rotation model or from random weights, train the full network on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz1FUnNxZkbC"
      },
      "source": [
        "# Extra Credit (13 points)\n",
        "\n",
        "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
        "\n",
        "- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
        "- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
        "  \n",
        "- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTCZzKEbZkbC"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
